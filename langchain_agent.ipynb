{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1443e7b",
   "metadata": {},
   "source": [
    "<h2><b>Langchain : Agent</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa715ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1 , doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62610d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027B7ABF9C70>, search_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000 , chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "vectordb = FAISS.from_documents(documents,GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b3724c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith_Search'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"Langsmith_Search\",\n",
    "    \"Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool\"\n",
    ")\n",
    "\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "758ea73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arxiv Tool- Website where all the Research papers Uploaded\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(arxiv_wrapper = arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93dcbdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\New Folder\\\\Main\\\\Coding\\\\Python\\\\Data Science\\\\Projects\\\\Practice\\\\GenAI\\\\langchain Campusx\\\\langcamp\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='Langsmith_Search', description='Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000027B69FE0180>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027B7ABF9C70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000027B6A2C9800>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027B7ABF9C70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0c827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
    "\n",
    "# from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=\"google/flan-t5-large\",  # Safe model\n",
    "#     task=\"text2text-generation\"\n",
    "# )\n",
    "# llm = ChatHuggingFace(llm=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d54d0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\New Folder\\Main\\Coding\\Python\\Data Science\\Projects\\Practice\\GenAI\\langchain Campusx\\langcamp\\Lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], input_types={}, partial_variables={}, template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'), additional_kwargs={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe4989f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000027B69CF99E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': [], 'tools': 'wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query., args: {\\'query\\': {\\'description\\': \\'query to look up on wikipedia\\', \\'title\\': \\'Query\\', \\'type\\': \\'string\\'}}\\narxiv - A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query., args: {\\'query\\': {\\'description\\': \\'search query to look up\\', \\'title\\': \\'Query\\', \\'type\\': \\'string\\'}}\\nLangsmith_Search(query: \\'str\\', *, retriever: \\'BaseRetriever\\' = VectorStoreRetriever(tags=[\\'FAISS\\', \\'GoogleGenerativeAIEmbeddings\\'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027B7ABF9C70>, search_kwargs={}), document_prompt: \\'BasePromptTemplate\\' = PromptTemplate(input_variables=[\\'page_content\\'], input_types={}, partial_variables={}, template=\\'{page_content}\\'), document_separator: \\'str\\' = \\'\\\\n\\\\n\\', callbacks: \\'Callbacks\\' = None, response_format: \"Literal[\\'content\\', \\'content_and_artifact\\']\" = \\'content\\') -> \\'Union[str, tuple[str, list[Document]]]\\' - Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool, args: {\\'query\\': {\\'description\\': \\'query to look up in retriever\\', \\'title\\': \\'Query\\', \\'type\\': \\'string\\'}}', 'tool_names': 'wikipedia, arxiv, Langsmith_Search'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'structured-chat-agent', 'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], input_types={}, partial_variables={}, template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'), additional_kwargs={})])\n",
       "| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-pro-latest', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000027B7ADEDDC0>, default_metadata=()), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| JSONAgentOutputParser()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agents\n",
    "from langchain.agents import create_structured_chat_agent\n",
    "\n",
    "agent =create_structured_chat_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2ba7310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000027B69CF99E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': [], 'tools': 'wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query., args: {\\'query\\': {\\'description\\': \\'query to look up on wikipedia\\', \\'title\\': \\'Query\\', \\'type\\': \\'string\\'}}\\narxiv - A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query., args: {\\'query\\': {\\'description\\': \\'search query to look up\\', \\'title\\': \\'Query\\', \\'type\\': \\'string\\'}}\\nLangsmith_Search(query: \\'str\\', *, retriever: \\'BaseRetriever\\' = VectorStoreRetriever(tags=[\\'FAISS\\', \\'GoogleGenerativeAIEmbeddings\\'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027B7ABF9C70>, search_kwargs={}), document_prompt: \\'BasePromptTemplate\\' = PromptTemplate(input_variables=[\\'page_content\\'], input_types={}, partial_variables={}, template=\\'{page_content}\\'), document_separator: \\'str\\' = \\'\\\\n\\\\n\\', callbacks: \\'Callbacks\\' = None, response_format: \"Literal[\\'content\\', \\'content_and_artifact\\']\" = \\'content\\') -> \\'Union[str, tuple[str, list[Document]]]\\' - Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool, args: {\\'query\\': {\\'description\\': \\'query to look up in retriever\\', \\'title\\': \\'Query\\', \\'type\\': \\'string\\'}}', 'tool_names': 'wikipedia, arxiv, Langsmith_Search'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'structured-chat-agent', 'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], input_types={}, partial_variables={}, template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'), additional_kwargs={})])\n",
       "| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-pro-latest', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000027B7ADEDDC0>, default_metadata=()), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| JSONAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\New Folder\\\\Main\\\\Coding\\\\Python\\\\Data Science\\\\Projects\\\\Practice\\\\GenAI\\\\langchain Campusx\\\\langcamp\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='Langsmith_Search', description='Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000027B69FE0180>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027B7ABF9C70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000027B6A2C9800>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027B7ABF9C70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a5a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472ca209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\":\"Tell me about Attention all you need\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63d1b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\":\"Tell me about the History of India\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "873a34d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I can use wikipedia to get information about Machine Learning.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Machine learning\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Machine learning (ML) is a field of study in artificial intelligence that allows computers to learn from data without explicit programming. It involves developing algorithms and statistical models that enable computer systems to identify patterns, make predictions, and improve their performance over time based on the data they are exposed to.  Essentially, machine learning algorithms learn by identifying patterns in data and then using these patterns to make informed decisions and predictions on new data.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Machine learning',\n",
       " 'output': 'Machine learning (ML) is a field of study in artificial intelligence that allows computers to learn from data without explicit programming. It involves developing algorithms and statistical models that enable computer systems to identify patterns, make predictions, and improve their performance over time based on the data they are exposed to.  Essentially, machine learning algorithms learn by identifying patterns in data and then using these patterns to make informed decisions and predictions on new data.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Machine learning\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
