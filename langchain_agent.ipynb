{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1443e7b",
   "metadata": {},
   "source": [
    "<h2><b>Langchain : Agent</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa715ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1 , doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62610d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3DB85DE80>, search_kwargs={})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000 , chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "vectordb = FAISS.from_documents(documents[:100],GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b3724c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith_Search'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"Langsmith_Search\",\n",
    "    \"Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool\"\n",
    ")\n",
    "\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "758ea73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arxiv Tool- Website where all the Research papers Uploaded\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(arxiv_wrapper = arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93dcbdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\New Folder\\\\Main\\\\Coding\\\\Python\\\\Data Science\\\\Projects\\\\Practice\\\\GenAI\\\\langchain Campusx\\\\langcamp\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='Langsmith_Search', description='Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001E3CAC5EA20>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3DB85DE80>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001E3CAF8C360>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3DB85DE80>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0c827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=\"google/flan-t5-large\",  # Safe model\n",
    "#     task=\"text2text-generation\"\n",
    "# )\n",
    "# llm = ChatHuggingFace(llm=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d54d0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\New Folder\\Main\\Coding\\Python\\Data Science\\Projects\\Practice\\GenAI\\langchain Campusx\\langcamp\\Lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe4989f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_function_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E3CA9C8EA0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E3CA9C8EA0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001E3FC5D1F70>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E3FC5D3B60>, root_client=<openai.OpenAI object at 0x000001E3FC35F6B0>, root_async_client=<openai.AsyncOpenAI object at 0x000001E3FC5D1FD0>, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'functions': [{'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}, {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}, {'name': 'Langsmith_Search', 'description': 'Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}]}, config={}, config_factories=[])\n",
       "| OpenAIFunctionsAgentOutputParser()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agents\n",
    "from langchain.agents import create_structured_chat_agent ,create_openai_functions_agent\n",
    "\n",
    "# agent =create_structured_chat_agent(llm,tools,prompt)\n",
    "agent = create_openai_functions_agent(llm,tools,prompt)\n",
    "# agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba7310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_function_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E3CA9C8EA0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E3CA9C8EA0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001E3FC5D1F70>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E3FC5D3B60>, root_client=<openai.OpenAI object at 0x000001E3FC35F6B0>, root_async_client=<openai.AsyncOpenAI object at 0x000001E3FC5D1FD0>, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'functions': [{'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}, {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}, {'name': 'Langsmith_Search', 'description': 'Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}]}, config={}, config_factories=[])\n",
       "| OpenAIFunctionsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\New Folder\\\\Main\\\\Coding\\\\Python\\\\Data Science\\\\Projects\\\\Practice\\\\GenAI\\\\langchain Campusx\\\\langcamp\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='Langsmith_Search', description='Search for the information about LangSmith, For any Question about Langsmith , you must have be using this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001E3CAC5EA20>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3DB85DE80>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001E3CAF8C360>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3DB85DE80>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "# agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87a5a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472ca209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Attention all you need Research Paper'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2023-03-02\n",
      "Title: Methods used in nanostructure modeling\n",
      "Authors: I. Camps\n",
      "Summary: How many times you need to change your method description because you were\n",
      "\"accused\" of plagiarism from text you already published? I will use this\n",
      "preprint to add all the methods I currently used in running the simulations for\n",
      "my research works. Then, I will cite it as needed.\n",
      "\n",
      "Published: 2022-07-05\n",
      "Title: Betti numbers of attention graphs is all you really need\n",
      "Authors: Laida Kushnareva, Dmitri Piontkovski, Irina Piontkovskaya\n",
      "Summary: We apply methods of topological analysis to the attention graphs, calculated\n",
      "on the attention heads of the BERT model ( arXiv:1810.04805v2 ). Our research\n",
      "shows that the classifier built upon basic persistent topological features\n",
      "(namely, Betti numbers) of the trained neural network can achieve\n",
      "classification results on par with the conventional classification method. We\n",
      "show the relevance of such topological text representation on three text\n",
      "classification benchmarks. For the best of our knowledge, it is the first\n",
      "attempt to analyze the topology of an attention-based neural network, widely\n",
      "used for Natural Language Processing.\n",
      "\n",
      "Published: 2024-11-14\n",
      "Title: Grounding is All You Need? Dual Temporal Grounding for Video Dialog\n",
      "Authors: You Qin, Wei Ji, Xinze Lan, Hao Fei, Xun Yang, Dan Guo, Roger Zimmermann, Lizi Liao\n",
      "Summary: In the realm of video dialog response generation, the understanding of video\n",
      "content and the temporal nuances of conversation history are paramount. While a\n",
      "segment of current research leans heavily on large-scale pretrained\n",
      "visual-language models and often overlooks temporal dynamics, another delves\n",
      "deep into spatial-temporal relationships within videos but demands intricate\n",
      "object trajectory pre-extractions and sidelines dialog temporal dynamics. This\n",
      "paper introduces the Dual Temporal Grounding-enhanced Video Dialog model\n",
      "(DTGVD), strategically designed to merge the strengths of both dominant\n",
      "approaches. It emphasizes dual temporal relationships by predicting dialog\n",
      "turn-specific temporal regions, filtering video content accordingly, and\n",
      "grounding responses in both video and dialog contexts. One standout feature of\n",
      "DTGVD is its heightened attention to chronological interplay. By recognizing\n",
      "and acting upon the dependencies between different dialog turns, it captures\n",
      "more nuanced conversational dynamics. To further bolster the alignment between\n",
      "video and dialog temporal dynamics, we've implemented a list-wise contrastive\n",
      "learning strategy. Within this framework, accurately grounded turn-clip\n",
      "pairings are designated as positive samples, while less precise pairings are\n",
      "categorized as negative. This refined classification is then funneled into our\n",
      "holistic end-to-end response generation mechanism. Evaluations using\n",
      "AVSD@DSTC-7 and AVSD@DSTC-8 datasets underscore the superiority of our\n",
      "methodology.\u001b[0m\u001b[32;1m\u001b[1;3mI found information on three research papers related to the phrase \"Attention all you need.\" Here are the details:\n",
      "\n",
      "1. Published: 2023-03-02\n",
      "   Title: Methods used in nanostructure modeling\n",
      "   Author: I. Camps\n",
      "   Summary: This paper discusses the methods used in nanostructure modeling for research works involving simulations.\n",
      "\n",
      "2. Published: 2022-07-05\n",
      "   Title: Betti numbers of attention graphs is all you really need\n",
      "   Authors: Laida Kushnareva, Dmitri Piontkovski, Irina Piontkovskaya\n",
      "   Summary: The research applies topological analysis methods to attention graphs derived from the BERT model. It shows that using basic persistent topological features (Betti numbers) can achieve classification results similar to conventional methods in Natural Language Processing.\n",
      "\n",
      "3. Published: 2024-11-14\n",
      "   Title: Grounding is All You Need? Dual Temporal Grounding for Video Dialog\n",
      "   Authors: You Qin, Wei Ji, Xinze Lan, Hao Fei, Xun Yang, Dan Guo, Roger Zimmermann, Lizi Liao\n",
      "   Summary: This paper introduces the Dual Temporal Grounding-enhanced Video Dialog model (DTGVD) that combines spatial-temporal relationships within videos with dialog temporal dynamics to generate responses in video dialog scenarios. The methodology focuses on chronological interplay and alignment between video and dialog temporal dynamics.\n",
      "\n",
      "If you need more specific information on any of these papers, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Attention all you need Research Paper',\n",
       " 'output': 'I found information on three research papers related to the phrase \"Attention all you need.\" Here are the details:\\n\\n1. Published: 2023-03-02\\n   Title: Methods used in nanostructure modeling\\n   Author: I. Camps\\n   Summary: This paper discusses the methods used in nanostructure modeling for research works involving simulations.\\n\\n2. Published: 2022-07-05\\n   Title: Betti numbers of attention graphs is all you really need\\n   Authors: Laida Kushnareva, Dmitri Piontkovski, Irina Piontkovskaya\\n   Summary: The research applies topological analysis methods to attention graphs derived from the BERT model. It shows that using basic persistent topological features (Betti numbers) can achieve classification results similar to conventional methods in Natural Language Processing.\\n\\n3. Published: 2024-11-14\\n   Title: Grounding is All You Need? Dual Temporal Grounding for Video Dialog\\n   Authors: You Qin, Wei Ji, Xinze Lan, Hao Fei, Xun Yang, Dan Guo, Roger Zimmermann, Lizi Liao\\n   Summary: This paper introduces the Dual Temporal Grounding-enhanced Video Dialog model (DTGVD) that combines spatial-temporal relationships within videos with dialog temporal dynamics to generate responses in video dialog scenarios. The methodology focuses on chronological interplay and alignment between video and dialog temporal dynamics.\\n\\nIf you need more specific information on any of these papers, feel free to ask!'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Attention all you need Research Paper\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\":\"Tell me about the History of India\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "873a34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\":\"Tell me about Machine learning\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
